{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies Loaded\n",
      "Driver Initiated\n",
      "Operation Complete\n"
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from config import salesusername, salespassword, gmailusername, gmailpassword, salesforcelanding\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "print(\"Dependencies Loaded\")\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver')\n",
    "print(\"Driver Initiated\")\n",
    "\n",
    "#Nagivate to Salesforce Login Url\n",
    "driver.get(salesforcelanding);\n",
    "userbox = driver.find_element_by_name('j_username')\n",
    "userbox.send_keys(salesusername)\n",
    "passbox = driver.find_element_by_name('j_password')\n",
    "passbox.send_keys(salespassword)\n",
    "logbutton = driver.find_element_by_name('_eventId_proceed')\n",
    "logbutton.click()\n",
    "\n",
    "#Nagivate to Google Suite Login Url\n",
    "driver.get('https://accounts.google.com/signin/v2');\n",
    "userbox = driver.find_element_by_class_name('whsOnd.zHQkBf')\n",
    "userbox.send_keys(gmailusername)\n",
    "nextbutton = driver.find_element_by_id('identifierNext')\n",
    "ActionChains(driver).click(nextbutton).perform()\n",
    "time.sleep(2)\n",
    "passbox = driver.find_element_by_name('password')\n",
    "passbox.send_keys(gmailpassword)\n",
    "nextbutton = driver.find_element_by_id('passwordNext')\n",
    "ActionChains(driver).click(nextbutton).perform()\n",
    "time.sleep(2)\n",
    "\n",
    "#go to gmail home\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "driver.get('https://mail.google.com/mail/u/0/#inbox')\n",
    "\n",
    "driver.get(salesforcelanding);\n",
    "print(\"Operation Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Back In (If Salesforce AutoLogs Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = \"\"\"\n",
    "\"\"\".split(\"\\n\")\n",
    "newnumbers = []\n",
    "for number in numbers:\n",
    "    print(number.replace(\"+1 \",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#login measures\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "driver.get(salesforcelanding);\n",
    "userbox = driver.find_element_by_name('j_username')\n",
    "userbox.send_keys(salesusername)\n",
    "passbox = driver.find_element_by_name('j_password')\n",
    "passbox.send_keys(salespassword)\n",
    "logbutton = driver.find_element_by_name('_eventId_proceed')\n",
    "logbutton.click()\n",
    "\n",
    "#Refresh the current variables for \"today\"; impacts emails later on\n",
    "if datetime.datetime.today().weekday() == 0:\n",
    "    day1 = \"Tues\"\n",
    "    day2 = \"Wednes\"\n",
    "elif datetime.datetime.today().weekday() == 1:\n",
    "    day1 = \"Wednes\"\n",
    "    day2 = \"Thurs\"\n",
    "elif datetime.datetime.today().weekday() == 2:\n",
    "    day1 = \"Thurs\"\n",
    "    day2 = \"Fri\"\n",
    "elif datetime.datetime.today().weekday() == 3:\n",
    "    day1 = \"Fri\"\n",
    "    day2 = \"Satur\"\n",
    "elif datetime.datetime.today().weekday() == 4:\n",
    "    day1 = \"Satur\"\n",
    "    day2 = \"Sun\"\n",
    "elif datetime.datetime.today().weekday() == 5:\n",
    "    day1 = \"Sun\"\n",
    "    day2 = \"Mon\"\n",
    "elif datetime.datetime.today().weekday() == 6:\n",
    "    day1 = \"Mon\"\n",
    "    day2 = \"Tues\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#p_s = soup.find_all('p')\n",
    "#for p in p_s:\n",
    "#    print(p.get_text()+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emailer(rec_email, rec_subject, rec_body):\n",
    "    driver.get(f'{work_email}{rec_email}')\n",
    "    time.sleep(3)\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    emailsubject = rec_subject\n",
    "    emailbody = rec_body\n",
    "    subjectbox = driver.find_element_by_class_name('aoT')\n",
    "    subjectbox.send_keys(emailsubject)\n",
    "    bodybox = driver.find_element_by_id(':nk')\n",
    "    bodybox.send_keys(emailbody)\n",
    "\n",
    "def execute_email(emailsubject, emailbody):\n",
    "    time.sleep(6)\n",
    "    driver.find_element_by_class_name('aoT').send_keys(emailsubject)\n",
    "    driver.find_element_by_id(':nk').send_keys(emailbody)\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_class_name('J-J5-Ji.J-JN-M-I-JG').click()\n",
    "    driver.find_element_by_class_name('J-J5-Ji.J-JN-M-I-JG').click()\n",
    "    driver.find_element_by_class_name('J-J5-Ji.J-JN-M-I-JG').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_class_name('J-N.J-Ph.CG').click()\n",
    "    driver.find_element_by_class_name('J-N.J-Ph.CG').click()\n",
    "    driver.find_element_by_class_name('J-N.J-Ph.CG').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_class_name('J-N.BB').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_id(':oy').click()\n",
    "\n",
    "def cls_button_locater(html_tables):    \n",
    "    #find the \"Open Activites\" table\n",
    "    for td_tag in range(len(html_tables)):\n",
    "        if html_tables[td_tag].find('td', class_='pbTitle').get_text() == \"Open Activities\":\n",
    "            #find the \"Cls\" Button\n",
    "            for t_row in html_tables[td_tag].find_all('tr'):\n",
    "                for a_tag in t_row.find_all('a'):\n",
    "                    if a_tag.get_text() == \"Cls\":\n",
    "                        driver.get(f\"\"\"{salesforcelanding}{str(a_tag).replace('<a class=\"actionLink\" href=\"/','').split('\"')[0]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"JC - \"\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "all_fwups = driver.find_elements_by_partial_link_text(f'{tag}')\n",
    "for fwup in all_fwups:\n",
    "    ActionChains(driver).key_down(Keys.COMMAND).click(fwup).key_up(Keys.COMMAND).perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "tag = \"JC - \"\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "all_fwups = driver.find_elements_by_partial_link_text(f'{tag}')\n",
    "for fwup in all_fwups:\n",
    "    ActionChains(driver).key_down(Keys.COMMAND).click(fwup).key_up(Keys.COMMAND).perform()\n",
    "dataset = []\n",
    "for x in driver.window_handles:\n",
    "    try:\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        taskdetail = soup.find('h2', class_=\"mainTitle\").get_text()\n",
    "        if taskdetail == \"Task Detail\":            \n",
    "            duedate = soup.find(\"div\", id=\"tsk4_ileinner\").get_text()\n",
    "            fwup = soup.find(\"div\", id=\"tsk5_ileinner\").get_text()\n",
    "            driver.find_element_by_xpath(\"/html/body/div/div/table/tbody/tr/td/div/div/div/table/tbody/tr/td/div/a\").click()\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        else:\n",
    "            duedate = \"new lead\"\n",
    "            fwup = \"\"\n",
    "        name = soup.find(\"div\", id=\"con2_ileinner\").get_text()\n",
    "        phone = soup.find(\"div\", id=\"con12_ileinner\").get_text()\n",
    "        if phone == \"\\xa0\":\n",
    "            phone = soup.find(\"div\", id=\"con13_ileinner\").get_text()\n",
    "        major = soup.find(\"div\", id=\"00N3600000LP34V_ileinner\").get_text()\n",
    "        createdby = soup.find('div', id='CreatedBy_ileinner').get_text().split(\" \")\n",
    "        initial_date = createdby[len(createdby) - 3]\n",
    "        url = driver.current_url\n",
    "        email = soup.find('div', id='con15_ileinner').get_text()\n",
    "        #populate dictionary with the mined data\n",
    "        fwupdict = {\n",
    "            \"fwup\":fwup,\n",
    "            \"name\":name,\n",
    "            \"major\":major,\n",
    "            \"duedate\":duedate,\n",
    "            \"initial date\":initial_date,\n",
    "            \"phone\":phone,\n",
    "            \"email\":\"\",\n",
    "            \"emailfwup\":\"\",\n",
    "            \"calltext\":\"\",\n",
    "            \"comments\":\"\",\n",
    "            \"newtask\":\"\",\n",
    "            \"date\":\"\",\n",
    "            \"time\":\"\",\n",
    "            \"status\":\"\",\n",
    "            \"url\":url,\n",
    "            \"leademail\":email\n",
    "        }\n",
    "        dataset.append(fwupdict)\n",
    "        driver.close()\n",
    "    except:\n",
    "        print('finished')\n",
    "        break\n",
    "df = pd.DataFrame(dataset)\n",
    "df.to_csv(f'fwups{date.today()}{tag}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Email\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Operation Complete\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Operation Complete\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Operation Complete\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Operation Complete\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Operation Complete\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Operation Complete\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Attempt failed; click manually\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Attempt failed; click manually\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Attempt failed; click manually\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Attempt failed; click manually\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Attempt failed; click manually\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Attempt failed; click manually\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Operation Complete\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Task Started\n",
      "typed subject\n",
      "typed date\n",
      "entered time\n",
      "Saved\n",
      "Operation Complete\n",
      "Operation Complete\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Skipping New Task\n",
      "Operation Complete\n",
      "Emails finished\n",
      "Operation Complete\n",
      "Skipping New Task\n",
      "Operation Complete\n"
     ]
    },
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument: missing command parameters\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-f80163bd33ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#make soup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentException\u001b[0m: Message: invalid argument: missing command parameters\n"
     ]
    }
   ],
   "source": [
    "newdf = pd.read_csv(\"fwups2020-12-07JC - .csv\")\n",
    "n = 0\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "#establish variable to allow for only 3 options; prevent errors\n",
    "errorprevention = 0\n",
    "#ask user if they're doing followups or new leads\n",
    "#New Note Module\n",
    "x = -1\n",
    "for url in newdf['url'].tolist():\n",
    "    driver.get(url)\n",
    "    x = x + 1\n",
    "    #make soup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "    #### EEEEEEE  M     M    A   II  LL\n",
    "    #### EE       MM   MM   A A  II  LL\n",
    "    #### EEEEEEE  M M M M  AAAAA II  LL\n",
    "    #### EE       M  M  M  A   A II  LL\n",
    "    #### EEEEEEE  M     M  A   A II  LLLLLLL\n",
    "    email_type = newdf['email'].tolist()[x]#input(\"Press 'Enter' to send email (or 'n' to skip): \")\n",
    "    email = newdf['leademail'].tolist()[x]\n",
    "    recipient = soup.find(\"div\", id=\"con2_ileinner\").get_text()\n",
    "    subjectinput = newdf['major'].tolist()[x]\n",
    "    subjectoutput = \"\"\n",
    "    if subjectinput == \"Data Analytics (M.S.)\":\n",
    "        subjectoutput = \"Master of Science in Data Analytics\"\n",
    "    elif subjectinput == \"Data Analytics - Cert\":\n",
    "        subjectoutput = \"Certificate in Data Analytics\"\n",
    "    elif subjectinput == \"Cyber Security & Privacy - Cert\":\n",
    "        subjectoutput = \"Certificate in Cyber Security\"\n",
    "    else:\n",
    "        print('!!!!!!!!!!!!! - Invalid Entry - Retry - !!!!!!!!!!!!!')\n",
    "        subjectoutput = input(\"Fix error: \")\n",
    "#    if email_type != \"n\":\n",
    "#        driver.get(f'{work_email}{email}')\n",
    "    if email_type == \"y\":\n",
    "        followup = newdf['emailfwup'].tolist()[x]\n",
    "        if followup == \"y\":\n",
    "            fwupsnippet = f'I just wanted to reach out to you one more time regarding your inquiry into our {subjectoutput}. '\n",
    "        elif followup == \"c\":\n",
    "            fwupsnippet = f\"I notice you previously asked for information on the {subjectoutput}. \"\n",
    "        else:\n",
    "            fwupsnippet = \"\"\n",
    "        driver.get(f'{work_email}{email}')\n",
    "        emailsubject = f'Earn a {subjectoutput} at The Catholic University of America'\n",
    "        bodytext = f\"\"\"Thank you for your interest in The Catholic University of America!\\n\\nMy name is John. {fwupsnippet}My role is to offer any help you may need to gather info and start an application.\\nTo start an application, click here: https://cardinaladmissions.force.com/TX_CommunitiesSelfReg?startURL=%2FTargetX_Portal__PB\\n\\n***Call us for a consultation to redeem your FREE application fee waiver!***\\nPlease indicate which day in the coming week you would prefer.\\n-(1)- {day1}day at 12:00pm or 3:30pm\\n-(2)- {day2}day at 2:00pm or 3:30pm\\n\\nIf none of the above times work for you, let me know when you're most available, and I'll schedule you for a special appointment.\"\"\"\n",
    "        emailbody = f\"{recipient}\\n\\n{bodytext}\"      \n",
    "        execute_email(emailsubject, emailbody)\n",
    "    elif email_type == \"s\":\n",
    "        subjectinput = soup.find(\"div\", id=\"00N3600000LP34V_ileinner\").get_text()\n",
    "        subjectoutput = \"\"\n",
    "        driver.get(f'{work_email}{email}')\n",
    "        errorprevention = 0\n",
    "        while errorprevention < 1:\n",
    "            if subjectinput == \"Data Analytics (M.S.)\":\n",
    "                subjectoutput = \"Master of Science in Data Analytics\"\n",
    "                sought_program = \"Degree Seeking\"\n",
    "                sought_school = \"School of Engineering\"\n",
    "                sought_deg = \"Data Analytics (M.S.)\"\n",
    "                errorprevention = errorprevention + 1\n",
    "            elif subjectinput == \"Data Analytics - Cert\":\n",
    "                subjectoutput = \"Certificate in Data Analytics\"\n",
    "                sought_program = \"Certificate\"\n",
    "                sought_school = \"School of Engineering Non-Degree\"\n",
    "                sought_deg = \"Data Analytics - Cert\"        \n",
    "                errorprevention = errorprevention + 1\n",
    "            elif subjectinput == \"Cyber Security & Privacy - Cert\":\n",
    "                subjectoutput = \"Certificate in Cyber Security\"\n",
    "                sought_program = \"Certificate\"\n",
    "                sought_school = \"School of Engineering Non-Degree\"\n",
    "                sought_deg = \"Cyber Security & Privacy - Cert\"        \n",
    "                errorprevention = errorprevention + 1\n",
    "            else:\n",
    "                errorprevention = errorprevention + 1\n",
    "                subjectoutput = \"Master of Science in Data Analytics\"\n",
    "                sought_program = \"Degree Seeking\"\n",
    "                sought_school = \"School of Engineering\"\n",
    "                sought_deg = \"Data Analytics (M.S.)\"\n",
    "                errorprevention = errorprevention + 1\n",
    "        #Greeting\n",
    "        driver.get(f'{work_email}{email}')\n",
    "        emailsubject = \"Data Analytics at CUA: Info You Requested\"\n",
    "        greet_text = \"          Thanks so much for speaking with me today.\\n\\n          I'll be sending you 3 emails in just a moment more in-depth info on the program: specifically - \\n\\n(1)How to Apply\\n(2)Class Overview/Brochure\\n(3)Other Offices/Resources at CUA\\n\\n          Thanks again for speaking with me. I think you'd make a great candidate and I look forward to hearing from you again soon!\"\n",
    "        emailbody = f\"{recipient}\\n\\n{greet_text}\"\n",
    "        execute_email(emailsubject, emailbody)\n",
    "        #Application Link\n",
    "        driver.get(f'{work_email}{email}')\n",
    "        emailsubject = f'Applying to Earn a {subjectoutput} at The Catholic University of America'\n",
    "        app_text = f\"          It was a pleasure speaking with you today. Based on our conversation, I think you're a good fit for our Master of Science in Data Analytics Degree program.\\n          To begin your application, follow this link: https://cardinaladmissions.force.com/TX_CommunitiesSelfReg?startURL=%2FTargetX_Portal__PB  \\n          You'll need to create a login. Once you've logged in, you'll want to make sure to pick the following options from the drop-down menus.\\n-{sought_program}\\n-{sought_school}\\n-{sought_deg}\\n-[Desired Semester] (i.e. Spring 2021)\\n          If you have any trouble completing the application, please call me at my office# (included below). I can walk you through the process.\\n         Thanks very much for speaking with me. I look forward to hearing from you soon!\"\n",
    "        emailbody = f\"\"\"{recipient}\\n\\n{app_text}\n",
    "        \"\"\"\n",
    "        #execute_email(emailsubject, emailbody)\n",
    "        #Brochure\n",
    "        driver.get(f'{work_email}{email}')\n",
    "        emailsubject = f'Data Analytics at CUA: Email Brochure'\n",
    "        broch_text = \"          To see the presentation we use for our weekly webinar on the program, visit: https://docs.google.com/presentation/d/1CxI03mMTERenu_sI3a6DP3uUH8F4PQkKbdewTSVBTnA/edit?usp=sharing\\n\\nVisit https://youtu.be/3tKYwsfXIUc to watch a recording of our weekly webinar covering the DA program.\\n\\nSee a list of available classes below. For more classes and a comprehensive overview, visit: https://metro.catholic.edu/academics/graduate/ms-data-analytics/index.html\\n\\nCore Classes (First 4/10 classes in the degree)\\n-----------------------------------------------------------------\\nDA 501: Introduction to Data Science and Python (3 credit hours)\\nA hands-on introduction to the field of Data Science and its applications. Covers a wide range of topics to provide an overview of the use of data in different fields. Provides hands-on practice with basic tools and methods of data analysis. Prepares students to use data in their field of study and in their work and to effectively communicate quantitative findings. Focus is on the use of Python in data analysis and mastering tools for acquiring, parsing, manipulating, and preparing data for statistical analysis.\\nDA 514: Applied Statistics and Data Analysis (3 credit hours)\\nThis is a second course in statistics. The course will focus on Design of experiments and Analysis of Variance, Categorical data analysis, Regression analysis, Time series/forecasting, and Data visualization.\\n\\nDA 515: Introduction to Machine Learning (3 credit hours)\\nThe course introduces principles, algorithms, and applications of machine learning from the point of view of modeling and prediction; formulation of learning problems; representation, over-fitting, generalization; clustering, classification, probabilistic modeling; and methods such as support vector machines, hidden Markov models, and Bayesian networks.\\n\\nDA 516: Applications of Data Analytics and Development (3 credit hours)\\nThe focus will be on programming and data manipulation techniques for constructing analytics-based applications.  Topics include SQL or no-SQL databases, using web service API’s to acquire data, introduction to Hadoop and MapReduce, and use of third-party analytic component API’s.\\n-----------------------------------------------------------------\\nMSDA Electives (Ask advisors about scheduling for electives in advance; electives are offered on a rotating basis; visit https://metro.catholic.edu/academics/graduate/ms-data-analytics/degree-requirement.html for a full list of electives\\n-----------------------------------------------------------------\\nCSC 447 - Artificial Intelligence (3 Credit Hours)\\nTopics may include state space search, heuristic search, knowledge representation techniques, expert systems, automated reasoning, definitions of intelligence, computer problem solving, game playing, pattern recognition, theorem proving, semantic information, processing, evolutionary systems, and heuristic programming. Prerequisite: Instructor's permission.\\n\\nCSC 410 - Fundamentals of Cloud Computing (3 Credit Hours)\\nOverview of the field of Cloud Computing, its enabling technologies, main building blocks, and hands-on experience through projects utilizing public cloud infrastructures, such as Amazon Web Services (AWS) and Microsoft Azure. Cloud computing services are being adopted widely across a variety of organizations in many domains. Simply, cloud computing is the delivery of computing as a service over a network, whereby distributed resources are rented, rather than owned, by an end user as a utility. Prerequisites: CSC 363 and CSC 323\\n\\nCSC 728 - Visualization (3 Credit Hours)\\nThe course focuses on visualization of scientific data. Both visualization principles and practical design issues are addressed. The course introduces the visualization pipeline. It covers the visualization of scalar data, vector data, and tensor data. It also covers image visualization, volume visualization and finally information visualization. It discusses the effective use of visualization in various areas of the natural sciences, and examples of application will be drawn from these areas. It emphasizes the importance of visualization in understanding observations, examining theories, and fostering new scientific hypothesis. representation and presentation, document visualization, and dynamic exploration Permission of instructor.\\n\\nCSC 651 - Multimedia Processing and Information Retrieval (3 Credit Hours)\\nThis course covers topics including multimedia systems, multimedia applications, image compression and processing, video compression and processing, content-based image retrieval, and content-based video indexing and retrieval. Prerequisite: EE 634 or Permission of instructor.\\n\\nCSC 641 - Data Mining (3 Credit Hours)\\nIntroduction to data mining techniques, including data preprocessing, data mining primitives, association rules, decision trees, cluster analysis, classification and machine learning, data visualization, and data warehousing. Applications from a wide variety of domains will be studied. Prerequisite: CSC 541 or Permission of instructor.\"\n",
    "        emailbody = f\"{recipient}\\n\\n{broch_text}\"\n",
    "        execute_email(emailsubject, emailbody)\n",
    "        #Resources\n",
    "        driver.get(f'{work_email}{email}')\n",
    "        emailsubject = f'Resources at CUA'\n",
    "        resource_text = \"          Included in this email are some important CUA resources for you to take advantage of.\\n\\nCAREER SERVICES:\\nhttps://success.catholic.edu/about-us/contact-us/index.html\\nPhone: 202-319-6262\\nEmail: success@cua.edu\\nENROLLMENT SERVICES:\\nhttps://enrollment-services.catholic.edu/contact-us/index.html\\nPhone: 202-319-5300\\nEmail: cua-enrollmentservices@cua.edu\\n\\nFINANCIAL AID SERVICES:\\nhttps://financial-aid.catholic.edu/contact-us/index.html\\nPhone: 202-319-5307\\nEmail: cua-finaid@cua.edu\"\n",
    "        emailbody = f\"{recipient}\\n\\n{resource_text}\"\n",
    "        execute_email(emailsubject, emailbody)\n",
    "    elif email_type == \"d\":\n",
    "        #APPLICATIONS SECTION\n",
    "        for td_tag in range(len(html_tables)):\n",
    "            myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "            #find the \"Applications\" table and save it's contents to the apps_table variable\n",
    "            if myvar == \"Applications\":\n",
    "                apps_table = html_tables[td_tag]\n",
    "        tdata = apps_table.find_all('tr')[2].find_all('td')\n",
    "        app_semester = tdata[3].get_text() +\" \"+ tdata[4].get_text()\n",
    "        driver.get(f'{work_email}{email}')\n",
    "        emailsubject = f\"Your Application to Catholic U's {subjectoutput}\"\n",
    "        deferral_text = f\"          This is John, from Catholic University of America. I hope you've been well!\\n\\n          We worked together on your {app_semester} application for the {subjectoutput} and you had expressed interested in deferring to Spring 2021 and there are still open seats left!\\n\\n          Please let me know if you'd like to enroll and I may be able to change your old app to Spring 2021. The deadline for submission is December 17th, 2020.\\n          Click here to start a new app: https://cardinaladmissions.force.com/\\n\\n          Thanks so much for your interest in our programs! I hope to speak to you soon.\"\n",
    "        emailbody = f\"{recipient}\\n\\n{deferral_text}\"\n",
    "        execute_email(emailsubject, emailbody)\n",
    "    elif email_type == \"q\":\n",
    "        driver.get(f'{work_email}{email}')\n",
    "        emailsubject = f\"CUA's {subjectoutput}: Check-In\"\n",
    "        qual_text = f\"          Hi there! This is John from CUA, just checking in about your interest in the {subjectoutput}. Based on our earlier conversation, I think you'd make a great candidate.\\n\\n          If you'd like to start an application, you can apply here: https://cardinaladmissions.force.com/TX_CommunitiesSelfReg?startURL=%2FTargetX_Portal__PB\\n\\n          Make sure to email me when you've begun, and I'll approve your $60 fee waiver.\\n          Thanks again for your interest in the program, and please feel free to reach out to me with any other questions you may have.\"\n",
    "        emailbody = f\"{recipient}\\n\\n{qual_text}\"\n",
    "        execute_email(emailsubject, emailbody)\n",
    "    elif email_type == \"n\":\n",
    "        print(\"Skipping Email\")\n",
    "        emailbody = \"(no email sent for this note)\"\n",
    "    else:\n",
    "        print(\"Invalid Key. Try Again.\")\n",
    "    print(\"Emails finished\")\n",
    "\n",
    "    #### NN   NN  OOOOOOO  TTTTTT EEEEEE\n",
    "    #### NNN  NN  OO   OO    TT   EE\n",
    "    #### NN N NN  OO   OO    TT   EEEEEE\n",
    "    #### NN  NNN  OO   OO    TT   EE\n",
    "    #### NN   NN  OOOOOOO    TT   EEEEEE\n",
    "    driver.get(url);\n",
    "    #find subjectline and commentsline strings from the df\n",
    "    subject = newdf['calltext'].tolist()[x]\n",
    "    comments = newdf['comments'].to_list()[x]\n",
    "    #determine the appropriate button to click\n",
    "    #execute click\n",
    "    if str(newdf['fwup'].tolist()[x]) != 'nan': \n",
    "        cls_button_locater(html_tables)\n",
    "    else:\n",
    "        while driver.current_url == url:\n",
    "            try:\n",
    "                driver.get(url)\n",
    "                driver.find_element_by_name('new').click()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                print('success')\n",
    "    #execute note\n",
    "    driver.find_element_by_name('tsk5').send_keys(f'JC - {subject}')\n",
    "    driver.find_element_by_name('tsk6').send_keys(f'{comments}\\n Email:\\n{emailbody}')\n",
    "    driver.find_element_by_name('save').click()            \n",
    "    print(\"Operation Complete\")\n",
    "    driver.get(url)\n",
    "    #New Task Module\n",
    "    if str(newdf['newtask'].tolist()[x]) != 'nan':\n",
    "        preventerror_url = driver.current_url\n",
    "        #INPUTFIELD\n",
    "        targetdate = str(newdf['date'].tolist()[x]).replace('\"','')#input(\"What date?(mm/dd): \")\n",
    "        targettime = str(newdf['time'].tolist()[x])#input('What time?(i.e. \"8\" or \"4\"): ')\n",
    "        subject = newdf['newtask'].tolist()[x]#input(\"Subject: \")\n",
    "        driver.switch_to.window(driver.window_handles[n])\n",
    "        driver.find_element_by_name('task').click()\n",
    "        while url == driver.current_url:\n",
    "            preventerror_url = driver.current_url\n",
    "            try:\n",
    "                driver.find_element_by_name('task').click()\n",
    "            except:\n",
    "                print('still trying')\n",
    "        print(\"Task Started\")\n",
    "        driver.find_element_by_name('tsk5').send_keys(f'JC - {subject}')\n",
    "        print(\"typed subject\")\n",
    "        driver.find_element_by_name('tsk4').send_keys(f'{targetdate}')\n",
    "        print(\"typed date\")\n",
    "        driver.find_element_by_name('reminder_dt_time').send_keys(targettime)\n",
    "        print(\"entered time\")\n",
    "        driver.find_elements_by_name('save')[1].click()\n",
    "        print(\"Saved\")\n",
    "        print(\"Operation Complete\")\n",
    "    else:\n",
    "        print(\"Skipping New Task\")\n",
    "    #Status Module\n",
    "    if newdf['status'].tolist()[x] != \"nan\":\n",
    "        newstatus = newdf['status'].tolist()[x]\n",
    "        try:\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            status = driver.find_element_by_id('00N0e000002cYq3_ilecell')\n",
    "            status.click()\n",
    "            status.send_keys(Keys.RETURN)\n",
    "            status.click()\n",
    "            time.sleep(1)\n",
    "            driver.find_element_by_id('00N0e000002cYq3').send_keys(newstatus)\n",
    "            status.click()\n",
    "            driver.find_element_by_name('inlineEditSave').click()\n",
    "            time.sleep(5)\n",
    "            print(\"Operation Complete\")\n",
    "        except:\n",
    "            print(\"Attempt failed; click manually\")\n",
    "    else:\n",
    "        print('Skipping Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "for td_tag in range(len(html_tables)):\n",
    "    myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "    #find the \"Recommendations\" table and save it's contents to the rec_table variable\n",
    "    if myvar == \"Open Activities\":\n",
    "        #tsk_table = html_tables[td_tag]\n",
    "        for t_row in html_tables[td_tag].find_all('tr'):\n",
    "            for a_tag in t_row.find_all('a'):\n",
    "                if a_tag.get_text() == \"Cls\":\n",
    "                    print(salesforcelanding+str(a_tag).replace('<a class=\"actionLink\" href=\"/','').split('\"')[0])\n",
    "a_tags = t_rows[2].find_all('a')\n",
    "cls_link = str(a_tags[1]).replace('<a class=\"actionLink\" href=\"','').split('\"')[0]\n",
    "print(f'{salesforcelanding}{cls_link}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "html_tables = soup\\\n",
    "              .find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "\n",
    "for td_tag in range(len(html_tables)):\n",
    "    myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "    #find the \"Recommendations\" table and save it's contents to the rec_table variable\n",
    "    if myvar == \"Open Activities\":\n",
    "        #tsk_table = html_tables[td_tag]\n",
    "        for t_row in html_tables[td_tag].find_all('tr'):\n",
    "            for a_tag in t_row.find_all('a'):\n",
    "                if a_tag.get_text() == \"Cls\":\n",
    "                    print(salesforcelanding+str(a_tag).replace('<a class=\"actionLink\" href=\"/','').split('\"')[0])\n",
    "a_tags = t_rows[2].find_all('a')\n",
    "cls_link = str(a_tags[1]).replace('<a class=\"actionLink\" href=\"','').split('\"')[0]\n",
    "print(f'{salesforcelanding}{cls_link}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for td_tag in range(len(BeautifulSoup(driver.page_source, 'html.parser')\\\n",
    ".find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\"))):\n",
    "    if BeautifulSoup(driver.page_source, 'html.parser')\\\n",
    "    .find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")[td_tag]\\\n",
    "    .find('td', class_='pbTitle').get_text() == \"Open Activities\":\n",
    "        for t_row in BeautifulSoup(driver.page_source, 'html.parser')\\\n",
    "        .find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")[td_tag]\\\n",
    "        .find_all('tr'):\n",
    "            for a_tag in t_row.find_all('a'):\n",
    "                if a_tag.get_text() == \"Cls\":\n",
    "                    print(salesforcelanding+str(a_tag).replace('<a class=\"actionLink\" href=\"/','').split('\"')[0])\n",
    "a_tags = t_rows[2].find_all('a')\n",
    "cls_link = str(a_tags[1]).replace('<a class=\"actionLink\" href=\"','').split('\"')[0]\n",
    "print(f'{salesforcelanding}{cls_link}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listylist = \"0 1 2\"\\\n",
    "            .split(' ')\n",
    "for litem in\\\n",
    "    listylist:\n",
    "    print(litem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "for td_tag in range(len(html_tables)):\n",
    "    myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "    #find the \"Activity History\" table and save it's contents to the rec_table variable\n",
    "    if myvar == \"Activity History\":\n",
    "        for t_row in html_tables[td_tag].find_all('tr'):\n",
    "            for in_tag in t_row.find_all('input'):\n",
    "                if str(in_tag).replace('<input class=\"btn\" ','').split('\" ')[0] == 'name=\"new':\n",
    "                    driver.get(f'''{salesforcelanding}{str(in_tag).replace(\"\"\"<input class=\"btn\" name=\"new\" onclick=\"navigateToUrl('/\"\"\",'').split('\" title=')[0]}''')\n",
    "                    \n",
    "\n",
    "#            \n",
    "#                if in_tag.get_text() == \"Cls\":\n",
    "#                    print(salesforcelanding+str(a_tag).replace('<a class=\"actionLink\" href=\"/','').split('\"')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "for td_tag in range(len(html_tables)):\n",
    "    myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "    #find the \"Recommendations\" table and save it's contents to the rec_table variable\n",
    "    if myvar == \"Open Activities\":\n",
    "        tsk_table = html_tables[td_tag]\n",
    "t_rows = tsk_table.find_all('tr')\n",
    "a_tags = t_rows[2].find_all('a')\n",
    "str(a_tags[1]).replace('<a class=\"actionLink\" href=\"','').split('\"')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = newdf['calltext'].tolist()[x]\n",
    "comments = newdf['comments'].to_list()[x]\n",
    "\n",
    "if close_or_new ==\"c\":\n",
    "    logbutton = \"Cls\"\n",
    "elif close_or_new ==\"l\":\n",
    "    logbutton = \"Log a Call\"\n",
    "\n",
    "preventerror_url = driver.current_url\n",
    "driver.find_element_by_partial_link_text(logbutton).click()\n",
    "while url == driver.current_url:\n",
    "    preventerror_url = driver.current_url\n",
    "    try:\n",
    "        driver.find_element_by_partial_link_text(logbutton).click()\n",
    "    except:\n",
    "        print('still trying')\n",
    "driver.find_element_by_name('tsk5').send_keys(f'JC - {subject}')\n",
    "driver.find_element_by_name('tsk6').send_keys(f'{comments}\\n Email:\\n{emailbody}')\n",
    "driver.find_element_by_name('save').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "nextbutton = soup.find('div', id='sbar-l-wrp').find('div', class_='b-pager').find('a', class_='b-pager-next').get_text()\n",
    "text = \"\"\n",
    "while nextbutton == 'Next':\n",
    "    try:\n",
    "        text = str(soup.find('div', id=\"content\").find('div', class_=\"b-story-body-x x-r15\").find(\"p\")).replace(\"<p>\",\"\").replace(\"</p>\",\"\").replace(\"<em>\",\"\").replace(\"</em>\",\"\").replace(\"<br>\",\"\\n\").replace(\"<br/>\",\"\")\n",
    "        text = text + storytext\n",
    "        driver.find_element_by_class_name('b-pager-next').click()\n",
    "        nextbutton = soup.find('div', id='sbar-l-wrp').find('div', class_='b-pager').find('a', class_='b-pager-next').get_text()\n",
    "    except:\n",
    "        print('an exception occurred')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.window(driver.window_handles[1])\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "rec_email = soup.find('div', id='ToAddress_ileinner').get_text()\n",
    "rec_subject = soup.find('div', id='Subject_ileinner').get_text()\n",
    "rec_body = soup.find('div', id='TextBody_ileinner').get_text()\n",
    "print(rec_email)\n",
    "print(rec_subject)\n",
    "print(rec_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver.switch_to.window(driver.window_handles[0])\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#find all of the tables in the html and put them in a list\n",
    "html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "#search the list for the headers/titles of each table;\n",
    "for td_tag in range(len(html_tables)):\n",
    "    myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "    #find the \"Recommendations\" table and save it's contents to the rec_table variable\n",
    "    if myvar == \"Recommendations\":\n",
    "        rec_table = html_tables[td_tag]\n",
    "#double check that rec_table is the right one\n",
    "table_name = rec_table.find('td', class_='pbTitle').get_text()\n",
    "#find all table rows inside of the recs table and save them to a list.\n",
    "t_rows = rec_table.find_all('tr')\n",
    "#t_rows = t_rows.pop(0)\n",
    "#print(t_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "incomp_rows = []\n",
    "for t_row in t_rows:\n",
    "#    print(f'\\n\\nindex: {ctr} {t_row}')\n",
    "    t_data = t_row.find_all('td', class_=\"dataCell\")\n",
    "    for t_datum in t_data:\n",
    "#        print(t_datum)\n",
    "        if t_datum.get_text() == \"Incomplete\":\n",
    "#            print(f\"incomplete found at: {ctr} {t_datum.get_text()}\")\n",
    "            incomp_rows.append(t_row)\n",
    "    ctr = ctr + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_recs = []\n",
    "for t_row in incomp_rows:\n",
    "    t_hrefs = t_row.find_all('a')\n",
    "    href = str(t_hrefs).split('\">Recommendation</a>,').pop(0).replace('[<a href=\"/','')\n",
    "    open_recs.append(href)\n",
    "open_recs\n",
    "#f'{salesforcelanding}{href}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.switch_to.window(driver.window_handles[0])\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#find all of the tables in the html and put them in a list\n",
    "html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "#search the list for the headers/titles of each table;\n",
    "for td_tag in range(len(html_tables)):\n",
    "    myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "    #find the \"Recommendations\" table and save it's contents to the rec_table variable\n",
    "    if myvar == \"Recommendations\":\n",
    "        rec_table = html_tables[td_tag]\n",
    "#double check that rec_table is the right one\n",
    "table_name = rec_table.find('td', class_='pbTitle').get_text()\n",
    "#find all table rows inside of the recs table and save them to a list.\n",
    "t_rows = rec_table.find_all('tr')\n",
    "#t_rows = t_rows.pop(0)\n",
    "#print(t_rows)\n",
    "incomp_rows = []\n",
    "for t_row in t_rows:\n",
    "    t_data = t_row.find_all('td', class_=\"dataCell\")\n",
    "    for t_datum in t_data:\n",
    "#        print(t_datum)\n",
    "        if t_datum.get_text() == \"Incomplete\":\n",
    "            incomp_rows.append(t_row)\n",
    "open_recs = []\n",
    "for t_row in incomp_rows:\n",
    "    t_hrefs = t_row.find_all('a')\n",
    "    href = str(t_hrefs).split('\">Recommendation</a>,').pop(0).replace('[<a href=\"/','')\n",
    "    open_recs.append(href)\n",
    "open_recs\n",
    "#f'{salesforcelanding}{href}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emailer(rec_email, rec_subject, rec_body):\n",
    "    driver.get(f'{work_email}{rec_email}')\n",
    "    time.sleep(3)\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    emailsubject = rec_subject\n",
    "    emailbody = rec_body\n",
    "    subjectbox = driver.find_element_by_class_name('aoT')\n",
    "    subjectbox.send_keys(emailsubject)\n",
    "    bodybox = driver.find_element_by_id(':nk')\n",
    "    bodybox.send_keys(emailbody)\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_class_name('J-J5-Ji.J-JN-M-I-JG').click()\n",
    "    driver.find_element_by_class_name('J-J5-Ji.J-JN-M-I-JG').click()\n",
    "    driver.find_element_by_class_name('J-J5-Ji.J-JN-M-I-JG').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_class_name('J-N.J-Ph.CG').click()\n",
    "    driver.find_element_by_class_name('J-N.J-Ph.CG').click()\n",
    "    driver.find_element_by_class_name('J-N.J-Ph.CG').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_class_name('J-N.BB').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_id(':oy').click()\n",
    "    time.sleep(5)\n",
    "\n",
    "for rec in open_recs:\n",
    "    driver.get(f'{salesforcelanding}{rec}')\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    grab_email = str(soup).split('<a href=\"mailto:')\n",
    "    rec_email = grab_email[1].split('\"')[0]\n",
    "    #driver.switch_to.window(driver.window_handles[0])\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    #find all of the tables in the html and put them in a list\n",
    "    html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "    #search the list for the headers/titles of each table;\n",
    "    for td_tag in range(len(html_tables)):\n",
    "        myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "        #find the \"Recommendations\" table and save it's contents to the rec_table variable\n",
    "        if myvar == \"Activity History\":\n",
    "            rec_table = html_tables[td_tag]\n",
    "    #double check that rec_table is the right one\n",
    "    table_name = rec_table.find('td', class_='pbTitle').get_text()\n",
    "    #find all table rows inside of the recs table and save them to a list.\n",
    "    t_body = rec_table.find_all('tbody')[1]\n",
    "    #print(t_body.prettify())\n",
    "    rec_href = str(t_body.find('a')).split('\"')[1]\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    driver.find_element_by_name('new').click()\n",
    "    while url == driver.current_url:\n",
    "        preventerror_url = driver.current_url\n",
    "    driver.find_element_by_name('tsk5').send_keys(f'JC - Email: {rec_subject}')\n",
    "    driver.find_element_by_name('save').click()\n",
    "    driver.get(f'{salesforcelanding}{rec_href}')\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    rec_email = soup.find('div', id='ToAddress_ileinner').get_text()\n",
    "    rec_subject = soup.find('div', id='Subject_ileinner').get_text()\n",
    "    rec_body = soup.find('div', id='TextBody_ileinner').get_text()\n",
    "    emailer(rec_email, rec_subject, rec_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.window(driver.window_handles[0])\n",
    "driver.find_element_by_name('new').click()\n",
    "while url == driver.current_url:\n",
    "    preventerror_url = driver.current_url\n",
    "driver.find_element_by_name('tsk5').send_keys(f'JC - Email: {rec_subject}')\n",
    "driver.find_element_by_name('save').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.switch_to.window(driver.window_handles[0])\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#find all of the tables in the html and put them in a list\n",
    "html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "#search the list for the headers/titles of each table;\n",
    "for td_tag in range(len(html_tables)):\n",
    "    myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "    #find the \"Recommendations\" table and save it's contents to the rec_table variable\n",
    "    if myvar == \"Activity History\":\n",
    "        rec_table = html_tables[td_tag]\n",
    "#double check that rec_table is the right one\n",
    "table_name = rec_table.find('td', class_='pbTitle').get_text()\n",
    "#find all table rows inside of the recs table and save them to a list.\n",
    "t_body = rec_table.find_all('tbody')[1]\n",
    "#print(t_body.prettify())\n",
    "rec_href = str(t_body.find('a')).split('\"')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.switch_to.window(driver.window_handles[0])\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#find all of the tables in the html and put them in a list\n",
    "html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "#search the list for the headers/titles of each table;\n",
    "for td_tag in range(len(html_tables)):\n",
    "    myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "    #find the \"Recommendations\" table and save it's contents to the rec_table variable\n",
    "    if myvar == \"Recommendations\":\n",
    "        rec_table = html_tables[td_tag]\n",
    "#double check that rec_table is the right one\n",
    "table_name = rec_table.find('td', class_='pbTitle').get_text()\n",
    "#find all table rows inside of the recs table and save them to a list.\n",
    "t_rows = rec_table.find_all('tr')\n",
    "#t_rows = t_rows.pop(0)\n",
    "#print(t_rows)\n",
    "incomp_rows = []\n",
    "for t_row in t_rows:\n",
    "    t_data = t_row.find_all('td', class_=\"dataCell\")\n",
    "    for t_datum in t_data:\n",
    "#        print(t_datum)\n",
    "        if t_datum.get_text() == \"Incomplete\":\n",
    "            incomp_rows.append(t_row)\n",
    "open_recs = []\n",
    "for t_row in incomp_rows:\n",
    "    t_hrefs = t_row.find_all('a')\n",
    "    href = str(t_hrefs).split('\">Recommendation</a>,').pop(0).replace('[<a href=\"/','')\n",
    "    open_recs.append(href)\n",
    "open_recs\n",
    "#f'{salesforcelanding}{href}'\n",
    "\n",
    "preventerror_url = driver.current_url\n",
    "driver.find_element_by_name('new').click()\n",
    "while url == driver.current_url:\n",
    "    preventerror_url = driver.current_url\n",
    "    driver.find_element_by_name('new').click()\n",
    "time.sleep(2)\n",
    "driver.find_element_by_name('tsk5').send_keys(f'JC - sent request emails for rec letters')\n",
    "driver.find_element_by_name('save').click()\n",
    "\n",
    "\n",
    "def emailer(rec_email, rec_subject, rec_body):\n",
    "    driver.get(f'{work_email}{rec_email}')\n",
    "    time.sleep(3)\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    emailsubject = rec_subject\n",
    "    emailbody = rec_body\n",
    "    subjectbox = driver.find_element_by_class_name('aoT')\n",
    "    subjectbox.send_keys(emailsubject)\n",
    "    bodybox = driver.find_element_by_id(':nk')\n",
    "    bodybox.send_keys(emailbody)\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_class_name('J-J5-Ji.J-JN-M-I-JG').click()\n",
    "    driver.find_element_by_class_name('J-J5-Ji.J-JN-M-I-JG').click()\n",
    "    driver.find_element_by_class_name('J-J5-Ji.J-JN-M-I-JG').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_class_name('J-N.J-Ph.CG').click()\n",
    "    driver.find_element_by_class_name('J-N.J-Ph.CG').click()\n",
    "    driver.find_element_by_class_name('J-N.J-Ph.CG').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_class_name('J-N.BB').click()\n",
    "    time.sleep(2)\n",
    "#    driver.find_element_by_id(':oy').click()\n",
    "    time.sleep(5)\n",
    "\n",
    "for rec in open_recs:\n",
    "    driver.get(f'{salesforcelanding}{rec}')\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    grab_email = str(soup).split('<a href=\"mailto:')\n",
    "    rec_email = grab_email[1].split('\"')[0]\n",
    "    #driver.switch_to.window(driver.window_handles[0])\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    #find all of the tables in the html and put them in a list\n",
    "    html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "    #search the list for the headers/titles of each table;\n",
    "    for td_tag in range(len(html_tables)):\n",
    "        myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "        #find the \"Recommendations\" table and save it's contents to the rec_table variable\n",
    "        if myvar == \"Activity History\":\n",
    "            rec_table = html_tables[td_tag]\n",
    "    #double check that rec_table is the right one\n",
    "    table_name = rec_table.find('td', class_='pbTitle').get_text()\n",
    "    #find all table rows inside of the recs table and save them to a list.\n",
    "    t_body = rec_table.find_all('tbody')[1]\n",
    "    #print(t_body.prettify())\n",
    "    rec_href = str(t_body.find('a')).split('\"')[1]\n",
    "    preventerror_url = driver.current_url\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_name('new').click()\n",
    "    while url == driver.current_url:\n",
    "        preventerror_url = driver.current_url\n",
    "    driver.find_element_by_name('tsk5').send_keys(f'JC - Email: Recommendation Requested')\n",
    "    driver.find_element_by_name('save').click()\n",
    "    driver.get(f'{salesforcelanding}{rec_href}')\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    rec_email = soup.find('div', id='ToAddress_ileinner').get_text()\n",
    "    rec_subject = soup.find('div', id='Subject_ileinner').get_text()\n",
    "    rec_body = soup.find('div', id='TextBody_ileinner').get_text()\n",
    "    emailer(rec_email, rec_subject, rec_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "preventerror_url = driver.current_url\n",
    "driver.find_element_by_name('new').click()\n",
    "print(f'{datetime}')\n",
    "while url == driver.current_url:\n",
    "    print(f'{datetime}')\n",
    "    preventerror_url = driver.current_url\n",
    "    print(f'{datetime}')\n",
    "driver.find_element_by_name('tsk5').send_keys(f'JC - sent request emails for rec letters')\n",
    "print(f'{datetime}')\n",
    "driver.find_element_by_name('save').click()\n",
    "print(f'{datetime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.get('https://cardinaladmissions-manager.my.salesforce.com/003?fcf=00B0e0000089y2h')\n",
    "#time.sleep(5)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "name_hrefs = soup.find_all('div', class_=\"x-grid3-cell-inner x-grid3-col-FULL_NAME\")\n",
    "len(name_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(name_hrefs) > 0:\n",
    "    href = str(name_hrefs[0]).split('><a href=\"/')[1].split('\"')[0]\n",
    "    print(f'{x}:{href}')\n",
    "    driver.get(f'{salesforcelanding}{href}')\n",
    "    #find all of the tables in the html and put them in a list\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "    for td_tag in range(len(html_tables)):\n",
    "        myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "        #find the \"Applications\" table and save it's contents to the apps_table variable\n",
    "        if myvar == \"Applications\":\n",
    "            apps_table = html_tables[td_tag]\n",
    "    #double check that apps_table is the right one\n",
    "    table_name = apps_table.find('td', class_='pbTitle').get_text()\n",
    "    print(table_name)\n",
    "    apps = apps_table.find_all('tr')#.find_all('th')\n",
    "#    print(apps.prettify())    \n",
    "#    for app in apps:\n",
    "#        print(app.prettify())\n",
    "    for x in range(len(apps)-2):\n",
    "        app = apps[x+2]\n",
    "        app_cols = app.find_all('td')\n",
    "        appdata = f'{app_cols[0].get_text()}    {app_cols[1].get_text()}    {app_cols[2].get_text()}    {app_cols[3].get_text()}    {app_cols[4].get_text()}'\n",
    "        print(appdata)\n",
    "    print('----------------------------------------------')\n",
    "    #search the list for the headers/titles of each table;\n",
    "    for td_tag in range(len(html_tables)):\n",
    "        myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "        #find the \"Activity History\" table and save it's contents to the acts_table variable\n",
    "        if myvar == \"Activity History\":\n",
    "            acts_table = html_tables[td_tag]\n",
    "    #double check that acts_table is the right one\n",
    "    table_name = acts_table.find('td', class_='pbTitle').get_text()\n",
    "    print(table_name)\n",
    "    notes = acts_table.find_all('tr')#.find_all('th')\n",
    "    for x in range(len(notes)-2):\n",
    "        note = notes[x+2]\n",
    "        note_text = note.find('th', class_='dataCell').get_text()\n",
    "        note_date = note.find('td', class_='dataCell DateElement').get_text()\n",
    "        print('----------------------------------------------')\n",
    "        print(f'{note_date}: {note_text}')\n",
    "    print('----------------------------------------------')\n",
    "    #Status Module\n",
    "    #INPUTFIELD\n",
    "    newstatus = input(\"Enter Appropriate Status: \")\n",
    "#        driver.switch_to.window(driver.window_handles[0])\n",
    "    status = driver.find_element_by_id('00N0e000002cYq3_ilecell')\n",
    "    status.click()\n",
    "    status.send_keys(Keys.RETURN)\n",
    "    try:\n",
    "        status.click()\n",
    "        time.sleep(1)\n",
    "        driver.find_element_by_id('00N0e000002cYq3').send_keys(newstatus)\n",
    "        status.click()\n",
    "        driver.find_element_by_name('inlineEditSave').click()\n",
    "        time.sleep(2)\n",
    "        print(\"Operation Complete\")\n",
    "    except:\n",
    "        try:\n",
    "            status.click()\n",
    "            driver.find_element_by_name('inlineEditSave').click()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            try:\n",
    "                status.click()\n",
    "                driver.find_element_by_name('inlineEditSave').click()\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                print(\"Attempt failed; click manually\")\n",
    "    reviewed_leads.append(href)\n",
    "    name_hrefs.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preserveident = 0\n",
    "if preserveident == 0:\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "    #search the list for the headers/titles of each table;\n",
    "    for td_tag in range(len(html_tables)):\n",
    "        myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "        #find the \"Activity History\" table and save it's contents to the acts_table variable\n",
    "        if myvar == \"Activity History\":\n",
    "            acts_table = html_tables[td_tag]\n",
    "    #double check that acts_table is the right one\n",
    "    table_name = acts_table.find('td', class_='pbTitle').get_text()\n",
    "    print(table_name)\n",
    "    notes = acts_table.find_all('tr')#.find_all('th')\n",
    "    for x in range(len(notes)-2):\n",
    "        note = notes[x+2]\n",
    "        note_text = note.find('th', class_='dataCell').get_text()\n",
    "        note_date = note.find('td', class_='dataCell DateElement').get_text()\n",
    "        print('----------------------------------------------')\n",
    "        print(f'{note_date}: {note_text}')\n",
    "    print('----------------------------------------------')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "preserveident = 0\n",
    "if preserveident == 0:\n",
    "    html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "    #search the list for the headers/titles of each table;\n",
    "    for td_tag in range(len(html_tables)):\n",
    "        myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "        #find the \"Applications\" table and save it's contents to the apps_table variable\n",
    "        if myvar == \"Applications\":\n",
    "            apps_table = html_tables[td_tag]\n",
    "    #double check that apps_table is the right one\n",
    "    table_name = apps_table.find('td', class_='pbTitle').get_text()\n",
    "    print(table_name)\n",
    "    apps = apps_table.find_all('tr')#.find_all('th')\n",
    "#    print(apps.prettify())    \n",
    "#    for app in apps:\n",
    "#        print(app.prettify())\n",
    "    for x in range(len(apps)-2):\n",
    "        app = apps[x+2]\n",
    "        app_cols = app.find_all('td')\n",
    "        print(f'{app_cols[0].get_text()}    {app_cols[1].get_text()}    {app_cols[2].get_text()}    {app_cols[3].get_text()}    {app_cols[4].get_text()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = [1,2,3,4,5,6,7,8,9,10]\n",
    "while len(mylist) > 0:\n",
    "    print(mylist[0])\n",
    "    mylist.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statlist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(statlistarchive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.get('https://cardinaladmissions-manager.my.salesforce.com/003?fcf=00B0e0000089y2h')\n",
    "#time.sleep(5)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "name_hrefs = soup.find_all('div', class_=\"x-grid3-cell-inner x-grid3-col-FULL_NAME\")\n",
    "len(name_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESUME HERE\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "href = str(name_hrefs[0]).split('><a href=\"/')[1].split('\"')[0]\n",
    "driver.get(f'{salesforcelanding}{href}')\n",
    "while len(name_hrefs) > 0:\n",
    "#    #NAVIGATION MODULE\n",
    "    href = str(name_hrefs[0]).split('><a href=\"/')[1].split('\"')[0]\n",
    "    print(f'currentpage:{href}')\n",
    "    driver.get(f'{salesforcelanding}{href}')\n",
    "\n",
    "    #find all of the tables in the html and put them in a list\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    html_tables = soup.find_all('div', class_=\"bPageBlock brandSecondaryBrd secondaryPalette\")\n",
    "    #APPLICATIONS SECTION\n",
    "    for td_tag in range(len(html_tables)):\n",
    "        myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "        #find the \"Applications\" table and save it's contents to the apps_table variable\n",
    "        if myvar == \"Applications\":\n",
    "            apps_table = html_tables[td_tag]\n",
    "    #double check that apps_table is the right one\n",
    "    table_name = apps_table.find('td', class_='pbTitle').get_text()\n",
    "    print(table_name)\n",
    "    apps = apps_table.find_all('tr')#.find_all('th')\n",
    "#    print(apps.prettify())    \n",
    "#    for app in apps:\n",
    "#        print(app.prettify())\n",
    "    for x in range(len(apps)-2):\n",
    "        app = apps[x+2]\n",
    "        app_cols = app.find_all('td')\n",
    "        print(f'{app_cols[0].get_text()}    {app_cols[1].get_text()}    {app_cols[2].get_text()}    {app_cols[3].get_text()}    {app_cols[4].get_text()}')\n",
    "    print('----------------------------------------------')\n",
    "    \n",
    "    #OPEN ACTIVITIES SECTION\n",
    "    for td_tag in range(len(html_tables)):\n",
    "        myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "        #find the \"Activity History\" table and save it's contents to the acts_table variable\n",
    "        if myvar == \"Open Activities\":\n",
    "            acts_table = html_tables[td_tag]\n",
    "    #double check that acts_table is the right one\n",
    "    table_name = acts_table.find('td', class_='pbTitle').get_text()\n",
    "    print(table_name)\n",
    "    notes = acts_table.find_all('tr')#.find_all('th')\n",
    "    for x in range(len(notes)-2):\n",
    "        note = notes[x+2]\n",
    "        note_text = note.find('th', class_='dataCell').get_text()\n",
    "        note_date = note.find('td', class_='dataCell DateElement').get_text()\n",
    "        print('----------------------------------------------')\n",
    "        print(f'{note_date}: {note_text}')\n",
    "    print('----------------------------------------------')\n",
    "\n",
    "    #search the list for the headers/titles of each table;\n",
    "    for td_tag in range(len(html_tables)):\n",
    "        myvar = html_tables[td_tag].find('td', class_='pbTitle').get_text()\n",
    "        #find the \"Activity History\" table and save it's contents to the acts_table variable\n",
    "        if myvar == \"Activity History\":\n",
    "            acts_table = html_tables[td_tag]\n",
    "    #double check that acts_table is the right one\n",
    "    table_name = acts_table.find('td', class_='pbTitle').get_text()\n",
    "    print(table_name)\n",
    "    notes = acts_table.find_all('tr')#.find_all('th')\n",
    "    for x in range(len(notes)-2):\n",
    "        note = notes[x+2]\n",
    "        note_text = note.find('th', class_='dataCell').get_text()\n",
    "        note_date = note.find('td', class_='dataCell DateElement').get_text()\n",
    "        print('----------------------------------------------')\n",
    "        print(f'{note_date}: {note_text}')\n",
    "    print('----------------------------------------------')\n",
    "    print(len(name_hrefs))\n",
    "    #Status Module\n",
    "    #INPUTFIELD\n",
    "    oldstatus = soup.find(\"div\", id=\"00N0e000002cYq3_ileinner\").get_text()\n",
    "    if oldstatus != \"Contacted\":\n",
    "        newstatus = oldstatus\n",
    "    else:\n",
    "        newstatus = input(\"Enter Appropriate Status: \")\n",
    "    statdict = {\"href\":href,\n",
    "                \"newstatus\":newstatus\n",
    "               }\n",
    "    statlist.append(statdict)\n",
    "    name_hrefs.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statlist[len(statlist)-2])\n",
    "print(statlist[len(statlist)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(statlist)-40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnewstatlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thissoup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "if thissoup.find(\"div\", id=\"00N0e000002cYq3_ileinner\").get_text() != \"Contacted\":\n",
    "    print(\"True\")\n",
    "else:\n",
    "    print(\"False\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stat in statlist:\n",
    "    href = stat[\"href\"]\n",
    "    newstatus = stat[\"newstatus\"]\n",
    "    print(href+\"  \"+newstatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.window(driver.window_handles[0])\n",
    "for stat in newnewstatlist:\n",
    "    href = stat[\"href\"]\n",
    "    newstatus = stat[\"newstatus\"]\n",
    "    driver.get(f'{salesforcelanding}{href}')\n",
    "    status = driver.find_element_by_id('00N0e000002cYq3_ilecell')\n",
    "    status.click()\n",
    "    status.send_keys(Keys.RETURN)\n",
    "    try:\n",
    "        status.click()\n",
    "        time.sleep(1)\n",
    "        driver.find_element_by_id('00N0e000002cYq3').send_keys(newstatus)\n",
    "        status.click()\n",
    "        driver.find_element_by_name('inlineEditSave').click()\n",
    "        time.sleep(2)\n",
    "        print(\"Operation Complete\")\n",
    "    except:\n",
    "        try:\n",
    "            status.click()\n",
    "            driver.find_element_by_name('inlineEditSave').click()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            try:\n",
    "                status.click()\n",
    "                driver.find_element_by_name('inlineEditSave').click()\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                print(\"Attempt failed; click manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appdata = f'{app_cols[0].get_text()}    {app_cols[1].get_text()}    {app_cols[2].get_text()}    {app_cols[3].get_text()}    {app_cols[4].get_text()}'\n",
    "print(appdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datelist = []\n",
    "for x in df['Created Date'].to_list():\n",
    "    h = x.split('-')\n",
    "    datelist.append(h[0]+\"-\"+h[1])\n",
    "datedf = pd.DataFrame({\"Created Date\":datelist,\n",
    "                      \"Application Number\":df[\"Application Number\"]})\n",
    "datedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 1: Set Up Google Calendar Appt (Mass Invite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google has no way to send mass invites to calendar appointments.\n",
    "#This module allows me to do that. Not critical to workflow, but helpful\n",
    "\n",
    "#Literally copy and paste a single column of email addresses from a csv/xls file\n",
    "names = \"\"\"agenesis09@gmail.com\n",
    "ahmed.y.mostafa@gmail.com\n",
    "henrymolina1@gmail.com\n",
    "hec.cen88@gmail.com\n",
    "jhabyara@yahoo.com\n",
    "pblake@scopemanagementllc.com\n",
    "ashida.morrison@gmail.com\n",
    "cdjenk14@gmail.com\n",
    "pallavisterling@gmail.com\n",
    "equalizer1@earthlink.net\n",
    "spn@princeton.edu\n",
    "mazzsj85@gmail.com\n",
    "freddykurian@gmail.com\n",
    "mgreenfield@strategiesfirst.com\n",
    "icollins@alvarezandmarsal.com\n",
    "richarddsouza001@hotmail.com\n",
    "ethanpr_24@hotmail.com\n",
    "marmck2002@yahoo.com\n",
    "nsanmi111@gmail.com\n",
    "ltheacock@gmail.com\n",
    "patrick.grobbel@fticonsulting.com\n",
    "soniammoore@yahoo.com\n",
    "mzbridge@gmail.com\n",
    "jhanikki@gmail.com\n",
    "gelawhenok@gmail.com\n",
    "archanap42_sap@yahoo.com\n",
    "mntdan0903@yahoo.com\n",
    "khawar.hussain78@gmail.com\n",
    "makonnenl2@gmail.com\n",
    "patildurgesh1998@gmail.com\n",
    "andrayray22@gmail.com\n",
    "armehraban@gmail.com\n",
    "pcoughlin@mail.com\n",
    "funmilaw9@gmail.com\n",
    "stmollett@gmail.com\n",
    "selamushega@gmail.com\n",
    "iballadares23@gmail.com\n",
    "emetanders@hotmail.com\n",
    "ike.kasiem@gmail.com\n",
    "bapimirabeau@yahoo.com\n",
    "nate@hypershift.com\n",
    "rcjones1316@gmail.com\n",
    "rachael.mcdonald.96@gmail.com\n",
    "eteklehimanot@gmail.com\n",
    "bhattapradip@yahoo.com\n",
    "samfl98@gmail.com\n",
    "akinlosotu89@gmail.com\n",
    "thoapham227@gmail.com\n",
    "aruntewary@yahoo.com\n",
    "zemichaelg@usa.net\n",
    "claudiovirginia@gmail.com\n",
    "willene.hare@gmail.com\n",
    "phegngi1@yahoo.com\n",
    "jsanders6613@gmail.com\n",
    "setapia88@gmail.com\n",
    "rizkallah_brandon@bah.com\n",
    "jtm@themccaingroup.us\n",
    "fortinb@protonmail.com\n",
    "johnnymara@gmail.com\n",
    "camcwilton@gmail.com\n",
    "bxmurphy@gmail.com\n",
    "anubhac@bu.edu\n",
    "atmalekinezhad@mix.wvu.edu\n",
    "marylizspud@gmail.com\n",
    "john.cloud@gmail.com\n",
    "drcaple@gmail.com\n",
    "rjrisse@gmail.com\n",
    "fsyed229@gmail.com\n",
    "joyce.johnson513@gmail.com\n",
    "jainsaner@gmail.com\n",
    "schirabay@gmail.com\n",
    "cejohnson@wmata.com\n",
    "teferra90@gmail.com\n",
    "shawn.howerton@icloud.com\n",
    "anmarjerjees23@gmail.com\n",
    "kevinbarry2000@msn.com\n",
    "keith.wooldridge@outlook.com\n",
    "yalcin.seyhan@yahoo.com\n",
    "janardandevkota17@gmail.com\n",
    "jorge@esveetech.com\n",
    "taylorlivesay1@gmail.com\n",
    "81grear@gmail.com\n",
    "c.duffus@gmail.com\n",
    "glenn.mossy@gmail.com\n",
    "yemundoro@gmail.com\n",
    "tgenanaw@gmail.com\n",
    "yasin.sebaggala@live.com\n",
    "kristin_tucker@trimble.com\n",
    "ramiro.ortega.landa@post.harvard.edu\n",
    "twhillman@gmail.com\n",
    "michellejiles@gmail.com\n",
    "xbpost@163.com\n",
    "mollagessesse@yahoo.com\n",
    "bibia@vcu.edu\n",
    "gregoryjdreher@gmail.com\n",
    "tajourdan@gmail.com\n",
    "i.b.okorie@gmail.com\n",
    "seb@batescainelli.com\n",
    "bwhalen524@gmail.com\n",
    "hellenmekonnen@yahoo.com\n",
    "esigie@esigie.com\n",
    "oracleconsultant001@gmail.com\n",
    "dmitry.rossoshansky@gmail.com\n",
    "karlazumaran@gmail.com\n",
    "bburton@ridgelineintl.com\n",
    "mcclain.jamal@yahoo.com\n",
    "cierralwaller@gmail.com\n",
    "myrica84@icloud.com\n",
    "davina1morris@gmail.com\n",
    "cinregan@gmail.com\n",
    "karencarvajal03@gmail.com\n",
    "nsnogren@gmail.com\n",
    "ewoldegeorgise@yahoo.com\n",
    "anmutonyi@aol.com\n",
    "mathieumears@gmail.com\n",
    "nfcmuhammad7@yahoo.com\n",
    "brendanlhwilson@gmail.com\n",
    "sanjayfgeorge@hotmail.com\n",
    "danielleodinicola@gmail.com\n",
    "demozebell@yahoo.com\n",
    "nbod16@gmail.com\n",
    "belay.samson@gmail.com\n",
    "litaibilbao@msn.com\n",
    "aiman.asad@outlook.com\n",
    "jkrt8260@gmail.com\n",
    "marsetadill@gmail.com\n",
    "vkamaha@gmail.com\n",
    "mainakeith@yahoo.com\n",
    "brittney.linds@gmail.com\n",
    "ritz4real2002@yahoo.com\n",
    "janaew95@yahoo.com\n",
    "riazhasanmd21228@gmail.com\n",
    "grescobar98@gmail.com\n",
    "fiona.kong@gmail.com\n",
    "inmanmj@gmail.com\n",
    "lbrown.mba@gmail.com\n",
    "carmengwalton@gmail.com\n",
    "a.moussou@yahoo.fr\n",
    "saidam1@umbc.edu\n",
    "konstantatou@gmail.com\n",
    "jonpetty10@gmail.com\n",
    "ldavis86@jhu.edu\n",
    "ehamner@gmail.com\n",
    "vita.washington@gmail.com\n",
    "tripjen@gmail.com\n",
    "veevhian@gmail.com\n",
    "ompong.trish@gmail.com\n",
    "klsokoloff@gmail.com\n",
    "benjaminwilson919@icloud.com\n",
    "klkashwojwala@gmail.com\n",
    "stephen.bryce@gmail.com\n",
    "jmcannadayus@yahoo.com\n",
    "kerrydj2@gmail.com\n",
    "siscor165@gmail.com\n",
    "seaydm@gmail.com\n",
    "carolina.leguizamo@gamil.com\n",
    "swtheberge@gmail.com\n",
    "pjpatti1975@yahoo.com\n",
    "lorendemp@aol.com\n",
    "dawitworkeneh@outlook.com\n",
    "purvahalarnkar@gmail.com\n",
    "mstanya04@gmail.com\n",
    "brandon.burns82291@gmail.com\n",
    "73mcquinn@cua.edu\n",
    "mrsdecker001@gmail.com\n",
    "jendsm@hotmail.com\n",
    "roger.reavis@gmail.com\n",
    "zelekemiz@gmail.com\n",
    "cargonzalez@comcast.net\n",
    "mccarthyjo@cua.edu\n",
    "heathermsc@yahoo.com\n",
    "atialael10@gmail.com\n",
    "scott_b_stephens@yahoo.com\n",
    "olusi.glory@gmail.com\n",
    "tim.pennington@outlook.com\n",
    "gbengameshy07@outlook.com\n",
    "mc.saif89rox@gmail.com\n",
    "p.sifundza@gmail.com\n",
    "melissaromero.s@gmail.com\n",
    "owenyang15@gmail.com\n",
    "narravula@yahoo.com\n",
    "rodzfe21@gmail.com\n",
    "dana7wheel@aol.com\n",
    "fikerte7@yahoo.com\n",
    "anienoidaresit@gmail.com\n",
    "leatm@yahoo.com\n",
    "yvonne.claytor@gmail.com\n",
    "elstondr@gmail.com\n",
    "addisu1tesfaye@gmail.com\n",
    "jmww2027@gmail.com\n",
    "ltucker595@aol.com\n",
    "kgtkv@aol.com\n",
    "jsebastian@infoleadsystems.com\n",
    "sniffend20@hsc.edu\n",
    "abdullah1204@gmail.com\n",
    "sogunle101@gmail.com\n",
    "euphrunwinlaugh@gmail.com\n",
    "m_curran99@outlook.com\n",
    "amokorme02@gmail.com\n",
    "vlewis1012@gmail.com\n",
    "arnoldkingiii@gmail.com\n",
    "nuzzath.khan@gmail.com\n",
    "costajhr@gmail.com\n",
    "ameriesh@gmail.com\n",
    "eamonn.hinchey@gmail.com\n",
    "pecooperinfotech@gmail.com\n",
    "halliwellawell@gmail.com\n",
    "cyoung13897@gmail.com\n",
    "anita.lama4444@gmail.com\n",
    "luvlee.0623@gmail.com\n",
    "durante.steve@gmail.com\n",
    "\"\"\".replace('\\n','\\n\\n\\n')\n",
    "#Navigate manually to the desired calendar page before executing this code\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "#time.sleep for 5 secs to allow operator to prepare\n",
    "time.sleep(5)\n",
    "#locate a valid field\n",
    "box = driver.find_element_by_class_name(\"T2Ybvb.KRoqRc.editable\")\n",
    "#manually click the invite field; this is the only way to enter data into it using Python;\n",
    "#the field refuses to respond to selenium attempts at targetting it directly\n",
    "f = \"\\n\"\n",
    "box.send_keys(f'1{f*5}2{f*5}3{f*5}4{f*5}5{f*5}6{f*5}7{f*5}8{f*5}9{f*5}10{f*5}@error.com\\n{names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'407-252-7069'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone = soup.find(\"div\", id=\"con12_ileinner\").get_text()\n",
    "if phone == \"\\xa0\":\n",
    "    phone = soup.find(\"div\", id=\"con13_ileinner\").get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Out App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
